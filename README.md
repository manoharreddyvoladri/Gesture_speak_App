---

# GestureSpeak: Bridging Communication Gaps with AI-Powered Sign Language Translation and Real-Time Video Conferencing

## **Overview**
GestureSpeak is an AI-powered platform designed to provide real-time sign language detection and translation. This application bridges communication gaps by integrating advanced deep learning models with a user-friendly interface. The system processes live video streams, detects sign language using YOLOv5, and translates it into text in real-time.

---

## **Features**
- **Real-Time Sign Detection**: Utilizes YOLOv5 for detecting and interpreting sign language with high accuracy.
- **Video Conferencing**: Supports seamless communication between users.
- **Secure Authentication**: Provides OTP-based secure user authentication.
- **Intuitive Interface**: Features a clean, professional UI for easy navigation.
- **Low Latency**: Enables real-time interaction with minimal delay.

---

## **Directory Structure**
```
manoharreddyvoladri-gesture_speak_app/
â”œâ”€â”€ _.crt
â”œâ”€â”€ app.py             # Main application file
â”œâ”€â”€ best.pt            # Pre-trained YOLOv5 model
â”œâ”€â”€ call.py            # Video conferencing functionality
â”œâ”€â”€ realtime.py        # Real-time sign detection logic
â”œâ”€â”€ requirements.txt   # Python dependencies
â”œâ”€â”€ server.crt         # SSL certificate
â”œâ”€â”€ server.key         # SSL private key
â”œâ”€â”€ vercel.json        # Deployment configuration
â”œâ”€â”€ Reports/           # Project-related documents
â”‚   â”œâ”€â”€ FINAL REVIEW.pptx
â”‚   â”œâ”€â”€ Project meetings.xlsx
â”‚   â”œâ”€â”€ REVIEW - 1.pptx
â”‚   â”œâ”€â”€ REVIEW.pptx
â”‚   â””â”€â”€ base papers/
â”œâ”€â”€ static/            # Static assets
â”‚   â”œâ”€â”€ css/
â”‚   â”‚   â”œâ”€â”€ dashboard.css
â”‚   â”‚   â”œâ”€â”€ room.css
â”‚   â”‚   â””â”€â”€ style.css
â”‚   â”œâ”€â”€ images/
â”‚   â””â”€â”€ js/
â”‚       â”œâ”€â”€ call.js
â”‚       â””â”€â”€ main.js
â”œâ”€â”€ templates/         # HTML templates
â”‚   â”œâ”€â”€ dashboard.html
â”‚   â”œâ”€â”€ error.html
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ index1.html
â”‚   â”œâ”€â”€ land.html
â”‚   â”œâ”€â”€ login.html
â”‚   â”œâ”€â”€ register.html
â”‚   â”œâ”€â”€ room.html
â”‚   â””â”€â”€ verify_otp.html
â””â”€â”€ test.py
```

---

## **Installation**

### **1. Prerequisites**
- Python 3.x installed on your system.
- `pip` (Python package installer) configured.
- A virtual environment (optional but recommended).

### **2. Clone the Repository**
```bash
git clone https://github.com/username/manoharreddyvoladri-gesture_speak_app.git
cd manoharreddyvoladri-gesture_speak_app
```

### **3. Install Dependencies**
Create a virtual environment (optional):
```bash
python -m venv venv
source venv/bin/activate   # On Windows: venv\Scripts\activate
```

Install the required packages:
```bash
pip install -r requirements.txt
```

---

## **Usage**

1. Run the main application:
   ```bash
   python app.py
   ```

2. Open the application in your browser:
   ```
   http://localhost:5000
   ```

3. **User Authentication**:
   - Register and log in using the provided forms.
   - Enter the OTP for secure authentication.

4. **Sign Language Detection**:
   - Navigate to the video conferencing feature.
   - Signs will be detected and translated into text in real-time.

5. **Real-Time Communication**:
   - Use the `call.py` script to enable video calls between users.

---

## **Dataset**
- **Hand Landmark Dataset**: Contains 6,500 images of American Sign Language (ASL) hand signs with 21 keypoints tracked for each hand pose.
- **Model**: Trained with YOLOv5 for high-accuracy real-time sign detection.

---

## **Technologies Used**
- **Backend**: Flask for handling server-side logic and routing.
- **Deep Learning**: YOLOv5 for object detection and VGG16 for classification.
- **Database**: MongoDB for user management.
- **Video Conferencing**: WebRTC integrated through custom scripts.

---

## **Deployment**
The application includes a `vercel.json` configuration for deployment on platforms like Vercel. Ensure all dependencies and configurations are properly set before deployment.

---

## **Conclusion**
GestureSpeak successfully demonstrates the integration of AI with real-time communication tools to enhance accessibility for the deaf and hard of hearing community. With its high accuracy, low latency, and user-friendly interface, GestureSpeak paves the way for inclusive digital interactions.

---

Let me know if you need further modifications! ðŸš€
